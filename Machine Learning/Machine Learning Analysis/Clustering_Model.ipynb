{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_reviews_per_rating(df):\n",
    "    # Membuat salinan DataFrame agar data asli tidak terubah\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Ubah string JSON menjadi dictionary\n",
    "    df_copy['reviews_per_rating'] = df_copy['reviews_per_rating'].apply(lambda x: json.loads(x.replace('null', '0')))\n",
    "    \n",
    "    # Pisahkan nilai dari dictionary ke kolom baru\n",
    "    df_copy['reviews_one_star'] = df_copy['reviews_per_rating'].apply(lambda x: x.get('1', 0))\n",
    "    df_copy['reviews_two_star'] = df_copy['reviews_per_rating'].apply(lambda x: x.get('2', 0))\n",
    "    df_copy['reviews_three_star'] = df_copy['reviews_per_rating'].apply(lambda x: x.get('3', 0))\n",
    "    df_copy['reviews_four_star'] = df_copy['reviews_per_rating'].apply(lambda x: x.get('4', 0))\n",
    "    df_copy['reviews_five_star'] = df_copy['reviews_per_rating'].apply(lambda x: x.get('5', 0))\n",
    "    df_copy.drop(columns=['reviews_per_rating'], inplace=True)\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_and_pca(df, n_components=3):\n",
    "    # column untuk imputasi\n",
    "    cols_to_impute = ['average_hour', 'std_hour', 'avg_popularity']\n",
    "    \n",
    "    # Mengganti 'Not Present' dengan NaN\n",
    "    df.replace('Not Present', np.nan, inplace=True)\n",
    "    \n",
    "    # Mengubah kolom yang bersangkutan menjadi tipe data float\n",
    "    df[cols_to_impute] = df[cols_to_impute].astype(float)\n",
    "    \n",
    "    # Inisialisasi KNNImputer\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    \n",
    "    # Menerapkan KNNImputer hanya pada kolom yang bersangkutan\n",
    "    df[cols_to_impute] = imputer.fit_transform(df[cols_to_impute])\n",
    "\n",
    "    # column untuk PCA\n",
    "    eda_cols = ['rating', 'reviews_one_star', 'reviews_two_star', \n",
    "            'reviews_three_star', 'reviews_four_star', \n",
    "            'reviews_five_star', 'average_hour', 'std_hour', \n",
    "            'avg_popularity', 'nearest_competitor_distance', 'nearest_competitor_rating'\n",
    "            ]\n",
    "    \n",
    "    # Inisialisasi MinMaxScaler dan PCA\n",
    "    scaler = MinMaxScaler()\n",
    "    pca = PCA(n_components=n_components)\n",
    "    \n",
    "    # Normalisasi dan PCA\n",
    "    matrix_columns = df[eda_cols].values\n",
    "    normalized_matrix = scaler.fit_transform(matrix_columns)\n",
    "    df[eda_cols] = normalized_matrix\n",
    "    principal_components = pca.fit_transform(df[eda_cols])\n",
    "    \n",
    "    # Membuat DataFrame dengan komponen utama\n",
    "    pca_columns = [f'PC{i+1}' for i in range(n_components)]\n",
    "    matrix_df = pd.DataFrame(data=principal_components, columns=pca_columns)\n",
    "    \n",
    "    # Menambahkan informasi place_id dan name ke DataFrame PCA\n",
    "    pca_df = pd.concat([df[['place_id', 'name']], matrix_df], axis=1)\n",
    "    \n",
    "    return pca_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(df, clusters_n=3, iteration_n=100):\n",
    "    # Kolom untuk clustering\n",
    "    list_col = ['PC1', 'PC2', 'PC3']\n",
    "\n",
    "    def update_centroids(points, assignments, clusters_n):\n",
    "        means = []\n",
    "        for c in range(clusters_n):\n",
    "            cluster_points = tf.gather(points, tf.reshape(tf.where(tf.equal(assignments, c)), [-1]))\n",
    "            mean = tf.reduce_mean(cluster_points, axis=0)\n",
    "            means.append(mean)\n",
    "        return tf.stack(means)\n",
    "    \n",
    "    # Membuat titik data menggunakan kolom yang telah dideklarasikan pada list_col\n",
    "    points = df[list_col].values\n",
    "    \n",
    "    # Membuat centroid awal dengan mengambil secara acak dari points\n",
    "    centroids = tf.Variable(tf.slice(tf.random.shuffle(points), [0, 0], [clusters_n, -1]))\n",
    "\n",
    "    # Loop untuk K-means\n",
    "    for step in range(iteration_n):\n",
    "        # Memperluas dimensi titik data dan centroid\n",
    "        points_expanded = tf.expand_dims(points, 0)\n",
    "        centroids_expanded = tf.expand_dims(centroids, 1)\n",
    "\n",
    "        # Menghitung jarak dan menentukan penugasan\n",
    "        distances = tf.reduce_sum(tf.square(points_expanded - centroids_expanded), axis=2)\n",
    "        assignments = tf.argmin(distances, axis=0)\n",
    "\n",
    "        # Memperbarui centroid\n",
    "        new_centroids = update_centroids(points, assignments, clusters_n)\n",
    "        centroids.assign(new_centroids)\n",
    "\n",
    "    # Menyimpan hasil cluster ke dataframe asli\n",
    "    df['cluster'] = assignments.numpy()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 21)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('./full_data.csv', nrows=100)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_id</th>\n",
       "      <th>name</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChIJd0EvQ4_zaS4ROHLtujX-hmE</td>\n",
       "      <td>Bebek Kaleyo Tebet</td>\n",
       "      <td>1.603264</td>\n",
       "      <td>-0.152479</td>\n",
       "      <td>-0.036636</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChIJEwwrrXH3aS4RcBo0XDRfOnc</td>\n",
       "      <td>McDonald's Puri Kembangan</td>\n",
       "      <td>1.240783</td>\n",
       "      <td>0.791657</td>\n",
       "      <td>0.306676</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChIJC_lABffzaS4RZGzb2lD-iAw</td>\n",
       "      <td>Setiabudi One</td>\n",
       "      <td>0.826325</td>\n",
       "      <td>0.262895</td>\n",
       "      <td>-0.113414</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChIJwZMcGHXxaS4RKdlMwHZXitw</td>\n",
       "      <td>KFC Gunawarman</td>\n",
       "      <td>0.794821</td>\n",
       "      <td>0.613140</td>\n",
       "      <td>0.045217</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChIJp5VZTgT0aS4R26oBEPT4nUw</td>\n",
       "      <td>Warung MJS</td>\n",
       "      <td>0.628640</td>\n",
       "      <td>0.230313</td>\n",
       "      <td>-0.244146</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ChIJqx7pL-L1aS4R95uqPW7IjcQ</td>\n",
       "      <td>NORU Rooftop Lounge Jakarta</td>\n",
       "      <td>-0.249412</td>\n",
       "      <td>-0.052334</td>\n",
       "      <td>-0.285920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ChIJmSM4FHH3aS4Rlx6b8sEdYvw</td>\n",
       "      <td>KFC</td>\n",
       "      <td>-0.375181</td>\n",
       "      <td>0.123148</td>\n",
       "      <td>-0.235661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ChIJcS82X8LxaS4RwYBPv9h5RU8</td>\n",
       "      <td>Bamsae bamsae</td>\n",
       "      <td>-0.253617</td>\n",
       "      <td>-0.175538</td>\n",
       "      <td>-0.045787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ChIJvVPyAonxaS4RO_IwkdRSeaY</td>\n",
       "      <td>Tuang Coffee</td>\n",
       "      <td>-0.432757</td>\n",
       "      <td>-0.167622</td>\n",
       "      <td>0.256594</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ChIJ3f_T5vz1aS4RGZiJM3a2sMQ</td>\n",
       "      <td>KAFE KOPI AA</td>\n",
       "      <td>-0.485672</td>\n",
       "      <td>-0.081179</td>\n",
       "      <td>0.039605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       place_id                         name       PC1  \\\n",
       "0   ChIJd0EvQ4_zaS4ROHLtujX-hmE           Bebek Kaleyo Tebet  1.603264   \n",
       "1   ChIJEwwrrXH3aS4RcBo0XDRfOnc    McDonald's Puri Kembangan  1.240783   \n",
       "2   ChIJC_lABffzaS4RZGzb2lD-iAw                Setiabudi One  0.826325   \n",
       "3   ChIJwZMcGHXxaS4RKdlMwHZXitw               KFC Gunawarman  0.794821   \n",
       "4   ChIJp5VZTgT0aS4R26oBEPT4nUw                   Warung MJS  0.628640   \n",
       "..                          ...                          ...       ...   \n",
       "95  ChIJqx7pL-L1aS4R95uqPW7IjcQ  NORU Rooftop Lounge Jakarta -0.249412   \n",
       "96  ChIJmSM4FHH3aS4Rlx6b8sEdYvw                          KFC -0.375181   \n",
       "97  ChIJcS82X8LxaS4RwYBPv9h5RU8                Bamsae bamsae -0.253617   \n",
       "98  ChIJvVPyAonxaS4RO_IwkdRSeaY                 Tuang Coffee -0.432757   \n",
       "99  ChIJ3f_T5vz1aS4RGZiJM3a2sMQ                 KAFE KOPI AA -0.485672   \n",
       "\n",
       "         PC2       PC3  cluster  \n",
       "0  -0.152479 -0.036636        2  \n",
       "1   0.791657  0.306676        2  \n",
       "2   0.262895 -0.113414        2  \n",
       "3   0.613140  0.045217        2  \n",
       "4   0.230313 -0.244146        2  \n",
       "..       ...       ...      ...  \n",
       "95 -0.052334 -0.285920        0  \n",
       "96  0.123148 -0.235661        0  \n",
       "97 -0.175538 -0.045787        0  \n",
       "98 -0.167622  0.256594        1  \n",
       "99 -0.081179  0.039605        0  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_copy = split_reviews_per_rating(df)\n",
    "# df_pca = impute_and_pca(df_copy)\n",
    "# perform_clustering(df_pca)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd8184b07a6c48f6036b4e01a40e4497d4c5d7fa4a24eab483af408316982bec"
  },
  "kernelspec": {
   "display_name": "Python 3.10.13 64-bit ('py310': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
